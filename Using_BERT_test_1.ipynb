{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "colab_type": "code",
        "id": "fvFvBLJV0Dkv",
        "outputId": "140119e5-4cee-4604-c0d2-be279c18b125"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQ-42fh0hjsF"
      },
      "source": [
        "## Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cyoj29J24hPX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"D:\\pan20-authorship-verification-training-small\\pan20-authorship-verification-training-small.jsonl\", lines = True)\n",
        "df_labels = pd.read_json(\"D:\\pan20-authorship-verification-training-small\\pan20-authorship-verification-training-small-truth.jsonl\", lines = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>fandoms</th>\n",
              "      <th>pair</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52596</th>\n",
              "      <td>3926a1bd-6d33-5513-a694-12d7590443d4</td>\n",
              "      <td>[True Blood, Austin &amp; Ally]</td>\n",
              "      <td>[Enjoy! And time stands still beneath the air ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52597</th>\n",
              "      <td>17227d87-a3cb-5aca-b5fd-bb642e88b030</td>\n",
              "      <td>[True Blood, Kuroko no Basuke/黒子のバスケ]</td>\n",
              "      <td>[\"I forgive you,\" she blurted out looking stra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52598</th>\n",
              "      <td>0332dcaa-7230-508b-badb-820f9d8eebaa</td>\n",
              "      <td>[Austin &amp; Ally, Five Nights at Freddy´s]</td>\n",
              "      <td>[\"What? Why? What\"s happening? Where are we go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52599</th>\n",
              "      <td>f5e4884a-13fd-51fb-a880-053d6655d59a</td>\n",
              "      <td>[Five Nights at Freddy´s, Austin &amp; Ally]</td>\n",
              "      <td>[\"Gah!\" I growled. \"I need a password to acces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52600</th>\n",
              "      <td>900c4a19-e22b-59fd-9cc7-8490919b1696</td>\n",
              "      <td>[Five Nights at Freddy´s, Austin &amp; Ally]</td>\n",
              "      <td>[Chica heard a noise below her and saw Golden ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         id  \\\n",
              "52596  3926a1bd-6d33-5513-a694-12d7590443d4   \n",
              "52597  17227d87-a3cb-5aca-b5fd-bb642e88b030   \n",
              "52598  0332dcaa-7230-508b-badb-820f9d8eebaa   \n",
              "52599  f5e4884a-13fd-51fb-a880-053d6655d59a   \n",
              "52600  900c4a19-e22b-59fd-9cc7-8490919b1696   \n",
              "\n",
              "                                        fandoms  \\\n",
              "52596               [True Blood, Austin & Ally]   \n",
              "52597     [True Blood, Kuroko no Basuke/黒子のバスケ]   \n",
              "52598  [Austin & Ally, Five Nights at Freddy´s]   \n",
              "52599  [Five Nights at Freddy´s, Austin & Ally]   \n",
              "52600  [Five Nights at Freddy´s, Austin & Ally]   \n",
              "\n",
              "                                                    pair  \n",
              "52596  [Enjoy! And time stands still beneath the air ...  \n",
              "52597  [\"I forgive you,\" she blurted out looking stra...  \n",
              "52598  [\"What? Why? What\"s happening? Where are we go...  \n",
              "52599  [\"Gah!\" I growled. \"I need a password to acces...  \n",
              "52600  [Chica heard a noise below her and saw Golden ...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()\n",
        "#df['pair'][0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMVE3waNhuNj"
      },
      "source": [
        "We take first 2,000 and last 2,000 sentences from the dataset to ensure uniform distribution of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gTM3hOHW4hUY"
      },
      "outputs": [],
      "source": [
        "batch_1 = pd.concat([df[:2000], df[-2000:]])\n",
        "#batch_1.reset_index(drop=True, inplace=True)\n",
        "batch_1_labels = pd.concat([df_labels[:2000], df_labels[-2000:]])\n",
        "#batch_1_labels.reset_index(drop=True, inplace=True)\n",
        "batch_1_labels['same'] = batch_1_labels['same'].astype(int) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "for p, pair in enumerate(batch_1['pair']):\n",
        "    #for i, text in enumerate(pair):\n",
        "    #    pair[i] = text[0:250]\n",
        "    batch_1['pair'][p] = ' [SEP] '.join(pair)\n",
        "\"\"\"\n",
        "# code for splitting before tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PRc2L89hh1Tf"
      },
      "source": [
        "We check how many pairs are labeled as `same` (value 1) and how many are labeled `different` (having the value 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "jGvcfcCP5xpZ",
        "outputId": "4c4a8afc-1035-4b21-ba9a-c4bb6cfc6347"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    2000\n",
              "0    2000\n",
              "Name: same, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_1_labels['same'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "## Loading the Pre-trained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "q1InADgf5xm2",
        "outputId": "dbc52856-4d52-42f8-8a74-a89944280a02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# DistilBERT:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# BERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "# Avoid unnecessary warnings\n",
        "ppb.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZDBMn3wiSX6"
      },
      "source": [
        "The variable `model` holds a pretrained BERT model.\n",
        "\n",
        "## Model #1: Preprocessing and Tokenization\n",
        "\n",
        "Tokenization is performed using BertTokenizer and may take 7-10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized = batch_1['pair'].apply((lambda x: tokenizer(text = x[0], text_pair = x[1],\n",
        "add_special_tokens=True, truncation=True, max_length=40, return_tensors=\"pt\").to(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  5670,  1037,  2978,  1010, 23625,  5599,  2026,  2159,\n",
              "         14957,  2013,  2028, 13547,  2000,  1996,  2060,  1011,  1011,  2021,\n",
              "           102,  1000,  2035,  2097,  2468,  2028,  2007,  3607,  1010,  1000,\n",
              "          2002,  2056,  1010,  2471,  3432,  1010,  2010, 15138, 18823,   102]],\n",
              "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized[0] #let's check what the tokenized input looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenized.index = np.arange(0, len(tokenized))\n",
        "#tokenized = tokenized.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#re-indexing was required for some experiments, but not amymore. Use re-indexing when you iterate over enumerated rows. \n",
        "\n",
        "#tokenized_index[1999]\n",
        "#tokenized_index[2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "for i, pair in enumerate(tokenized):\n",
        "    #input_id = tokenized[pair]['input_ids']\n",
        "    #tokenized[i] = ' [SEP] '.join(pair['input_ids'])\n",
        "    #if i == 0:\n",
        "    #    print(i, \"PPAAAAIR\", pair)\n",
        "    #    print(\"000\", tokenized[i]['input_ids'])\n",
        "    #print(i)\n",
        "    texts = tokenized[i]['input_ids'][0] + tokenized[i]['input_ids'][1]\n",
        "    types = tokenized[i]['token_type_ids'][0] + tokenized[i]['token_type_ids'][1]\n",
        "    masks = tokenized[i]['attention_mask'][0] + tokenized[i]['attention_mask'][1]\n",
        "    if i > 1999:\n",
        "        #print(text)\n",
        "        tokenized[i]['input_ids'] = texts\n",
        "        tokenized[i]['token_type_ids'] = types\n",
        "        tokenized[i]['attention_mask'] = masks\n",
        "\"\"\"        \n",
        "\n",
        "# code for splitting after tokenization. Not used in batched processing.\\\n",
        "\n",
        "\"\"\"\n",
        "token_tensors = []\n",
        "for i, pair in enumerate(tokenized):\n",
        "    token_tensors.append(pair['input_ids'])\n",
        "\n",
        "token_tensors_df = pd.DataFrame(token_tensors)\n",
        "\"\"\"\n",
        "\n",
        "# code for extracting the encodings. Not used in batched processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "URn-DWJt5xhP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\"\"\"\n",
        "# code for padding when it is not performed during tokenization\n",
        "\n",
        "# to simulate padding:\n",
        "# padded = np.array([i for i in token_tensors_df.values])\n",
        "\n",
        "#np.array(padded).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "4K_iGRNa_Ozc",
        "outputId": "d03b0a9b-1f6e-4e32-831e-b04f5389e57c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape\n",
        "\"\"\"\n",
        "\n",
        "# adding attention mask if it is not performed during tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jK-CQB9-kN99"
      },
      "source": [
        "## Model #1 Learning\n",
        "\n",
        "The `model()` function runs our sentences through BERT (it is inherited by BERT's `forward()` function). The results of the processing will be returned into `all_output`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "39UVjAV56PJz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "print(device)\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "\"\"\"\n",
        "\n",
        "# standard training with separate, manually created encodings and attention masks (no batching => may require a lot of memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test model to try different modes \n",
        "\n",
        "test_input = tokenizer([\"Hello, my dog is cute\", \"And what now?\"], padding=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "type(test_input)\n",
        "model = model.to(\"cuda:0\")\n",
        "test_output = model(**test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4000, 40, 768])\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "\n",
        "\n",
        "all_outputs = torch.Tensor()\n",
        "all_outputs = all_outputs.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tokenized:\n",
        "        \n",
        "        #batch['input_ids'].to(device)              # not needed if CUDA was enabled during tokenization\n",
        "        #batch['token_type_ids'].to(device)\n",
        "        #batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(**batch)\n",
        "        all_outputs = torch.cat((all_outputs, outputs.last_hidden_state), 0)\n",
        "    print(all_outputs.shape)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model = model.to(device)\n",
        "\n",
        "#with torch.no_grad():\n",
        "#    features = tokenized.apply(lambda x: model(**x).last_hidden_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "Extract `[CLS]` tokens to used them as input to simple LogReg classifier and save them in the `features` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = all_outputs[:,0,:].cpu().numpy() # [:,0,:] meaning: ':' for all sequences, '0' for first token in sequence, ':' for all 768 hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_VZVU66Gurr-"
      },
      "source": [
        "The labels indicating which pair is written by the same author or by different ones go into the `labels` variable\n",
        "\n",
        "We also randomly permute labels and then permute features according to the same pattern. This is done to provide uniform distribution of lables after train/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JD3fX2yh6PTx"
      },
      "outputs": [],
      "source": [
        "labels = batch_1_labels['same']\n",
        "\n",
        "idx = np.random.permutation(labels.index)\n",
        "labels = labels.reindex(idx)\n",
        "features = pd.DataFrame(features)\n",
        "features = features.reindex(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iaoEvM2evRx1"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "We now split the obtained datset into a training set and testing set in standard proportion (75% to 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ddAqbkoU6PP9"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cyEwr7yYD3Ci"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 100.0}\n",
            "best scores:  0.6076666666666667\n"
          ]
        }
      ],
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scores: ', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "gG-EVWx4CzBc",
        "outputId": "9252ceff-a7d0-4359-fef9-2f72be89c7d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=97)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf = LogisticRegression(C=97)\n",
        "lr_clf.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "iCoyxRJ7ECTA",
        "outputId": "cfd86dea-5d16-476c-ab9b-47cbee3a014f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.603"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "lnwgmqNG7i5l",
        "outputId": "0042aed2-4fa8-4fa0-bf25-fdef70a10aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.503 (+/- 0.00)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EJQuqV6cnWQu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "A Visual Notebook to Using BERT for the First Time.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
